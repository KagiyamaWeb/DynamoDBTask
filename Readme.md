## Примерная цена хранения документа:

### Вес документа

    ```bash
    Numbers are variable length, with up to 38 significant digits. Leading and trailing zeroes are trimmed. The size of a number is approximately (length of attribute name) + (1 byte per two significant digits) + (1 byte).

    An attribute of type List or Map requires 3 bytes of overhead, regardless of its contents. The size of a List or Map is (length of attribute name) + sum (size of nested elements) + (3 bytes) . The size of an empty List or Map is (length of attribute name) + (3 bytes).
    ```

Мы возвращаем лист словарей где каждый элемент соответствует JSON схеме:
    ```bash
    {
        "u": 123456,
        "t": 1693440000,
        "v": [60, 61, 78, ...]
    }
    ```
    Используя тип данных Number Set (NS) мы получаем следующую структуру DynamoDB:
    ```bash
    {
        "u": {
            "N": "123456"
        },
        "t": {
            "N": "1693440000"
        },
        "v": {
            "NS": ["60", "61", "78", "23", "11", "10", "1", "7"...]
        }
    }
    ```

1. "u" user id, от 1 до 1 000 000:
1b длинна атрибута + (1b * (число signigicant digits / 2), т.е. от 1 до 3 байт, в среднем 2)
1 + 1*2 = 3

2. "t" timestamp. Таймстамп в нашем случае приходится на каждые 30 секунд, начиная от начала суток 00:00:00
Реалестично мы столкнемся с разбросом занчений 
~1699000000 -- 1998979200 (5/6/2033, 0:00:00 PM), это 2-4 байта, в среднем 3:
1 + 3 = 4


3. "v" activity_scores:
1b длинна атрибута "v", 3b overhead + 2880 = 8kb 640b + 2kb 880b (всего элементов)
1 + 3 + 2880 + 2880 = 5764

Итого: 3b + 4b + 5764b =~ 5.6289kb за один документ

### Схема:

```bash
Table Schema:

    Primary Key:
        Partition Key (u): User ID (integer)
        Sort Key (t): Timestamp (Unix timestamp as an integer)

    Attributes:
        v: Activity Scores (List of integers)
```

SH команда:

```shell
aws dynamodb create-table \
  --table-name UserActivityTable \
  --attribute-definitions AttributeName=u,AttributeType=N AttributeName=t,AttributeType=N \
  --key-schema AttributeName=u,KeyType=HASH AttributeName=t,KeyType=RANGE \
  --provisioned-throughput ReadCapacityUnits=5 WriteCapacityUnits=5 \
  --endpoint-url http://localhost:5555 \
  --global-secondary-indexes \
    "IndexName=GSI1,KeySchema=[{AttributeName=u,KeyType=HASH},{AttributeName=day-hour,KeyType=RANGE}],Projection={ProjectionType=INCLUDE,NonKeyAttributes=[v]}" \
  --attribute-definitions AttributeName=v,AttributeType=NS
```

### Стоимость содержания:

Мы посчитали выше, что в среднем документ весит 5.6289kb. Тогда для 1кк пользователей он будет весить 5628906.25kb или 5496.98mb

```bash

Учитываем только цену запросов на чтение и запись (без стоимости хранения и любых других фичей DynamoDB) и используем стандартный ценник:

    $1.25 per million write request units (WRU)

    $0.25 per million read request units (RRU)

    Как считаются WRU: 1 WRU на документ до 1 КБ с округлением вверх. То есть:
        для документов размером меньше 1 КБ для их записи потребуется ровно 1 WRU,
        для документов от 1 до 2 КБ потребуется ровно 2 WRU,
        и так далее: на каждый дополнительный 1 КБ нужен дополнительный 1 WRU.
        При записи в базу каждой отдельной записи WRU считаются отдельно.

    Как считаются RRU: 1 RRU на чтение до 4 КБ с округлением вверх. То есть:
        для документов размером меньше 4 КБ для их чтения потребуется ровно 1 RRU,
        для документов от 4 до 8 КБ потребуется ровно 2 RRU,
        и так далее: на каждые дополнительные 4 КБ нужен дополнительный 1 RRU.
        При чтении каждого отдельного документа RRU считаются отдельно.
```
Тогда:

На документ размером 5.6 кб (округление вверх 6) нам потребуется 6 WRU и 2RRU. Каждый день на приходят 2 запроса на чтение: 
1. получить список activity_scores за конкретный час любого дня
2. получить список activity_scores за конкретные 12 часов

Если хранить каждый документ целиком, то у нас выйдет 6WRU и 2RRU (при 1кк пользователей). За месяц получаем 180WRU и 60RRU 
т.е 

```bash
180 * 1.25 + 0.25 * 60 = 285$/мес.
```

### Оптимизация:

1. Учитывая расценки на WRU и RRU самый очевидный способ оптимизации это уменьшить вес документа. В предложеном варианте документа, например, используется 
минимально возможный размер аргумента, всего 1 символ. Другой способ заключается в использовании типа данных Number Set (NS) для списка чисел вместо обычного листа. Таким способом наш 

2. Для каждого юзера создавать 3 документа в день по 8 часов, в каждом 2880 / 3 = 960 значений. 
Таким образом мы уменьшим WRU и RRU:

Получаем три документа 1.9 кб за 00:00-08:00, 08:00-16:00 и 16:00-00:00 (округление вверх 2) нам потребуется 6 WRU что бы записать (на 1кк пользователей). 

Каждый день на приходят 2 запроса на чтение: 

1. получить список activity_scores за конкретный час любого дня (1 RRU)
- Делаем запрос по таймстемпу BETWEEN ... AND ... и получаем один документ с 8 часами весом 1.9 кб (1RRU)
Из него уже по тайстепам на стороне бекенда можем получить за конкретный час.

2. получить список activity_scores за конкретные 12 часов
- Делаем запрос по таймстемпу BETWEEN ... AND ..., получаем 2 документа весом 3.8 кб (1RRU). Так же обрабатываем на стороне бекнда на сервисе и
получаем из 16 часов всего 12 нужных часов

Итого 2 запроса на документ весом 6кб, 6WRU и 1RRU (при 1кк пользователей). 
За месяц получаем 180WRU и 30RRU
```bash
180 * 1.25 + 0.25 * 30 = 232.5$/мес.
```
### Почему не сделать документы больше?:

1. Как описано выше, если делать всё одиним доком, выйдет 6WRU и 2RRU. 
2. Если попоробовать разделить на два, то получатся 2 дока весом 
2.8кб, с окргулением 3. Те же самые WRU, а на чтение 1 RRU если 12-часовой период попал в наши границы (вероятность чего при прочих равных всего лишь 1/12), либо (что более вероятно) полные 2 за 2 дока, где мы найдем наш период.

### Почему не сделать документы меньше?

1. 4 документа по 6 часов у нас будут по 1.4кб. Всё те же 6WRU, но на чтении 12 часов мы минимум тратим по 1RRU, если два дока подряд точно попали во временной
промежуток (с 00:00 до 06:00, 06:00-12:00, 12:00-18:00, 18:00-00:00) т.е 4/24 = 1/6, но с вероятностью 5/6 мы тратим 2RRU

2. 6 доков по 4 часа по 0.93 то же самое, хоть вероятность и получше (6/24 = 1/4)

3. 12 доков по час не имеет смысла. Один док будет 0.475кб, но за его запись мы всё равно тратим 1WRU. Это 12WRU на всё.

4. Делить по нецелому часу не имеет смысла. Мы ожидаем только целые часы.

## Итого:
Делим каждый инпут на 3 документа по 960 значений каждый, получаем:
```bash
180 * 1.25 + 0.25 * 30 = 232.5$/мес.
```
